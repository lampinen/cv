% LaTeX file for resume 
% This file uses the resume document class (res.cls)

\documentclass[margin]{res} 
% the margin option causes section titles to appear to the left of body text 
\textwidth=5.2in % increase textwidth to get smaller right margin
%\usepackage{helvetica} % uses helvetica postscript font (download helvetica.sty)
%\usepackage{newcent}   % uses new century schoolbook postscript font 
\usepackage{url}
\begin{document} 
 
\name{Andrew Kyle Lampinen\\[14pt]}
 
\address{{\bf Email} \\ andrewlampinen@gmail.com}
\address{{\bf Website} \\\url{https://lampinen.github.io}}
\begin{resume} 
\section{Education} 
{\bf Stanford University,} Ph.D. Psychology (Cognitive), 2015-2020
\begin{itemize} \itemsep -2pt \item Center for Mind, Brain, Computation, and Technology Trainee. \item Minor in Computer Science.\end{itemize}
{\bf UC Berkeley,}  B.A. Mathematics \& Physics, 2010-2014%\begin{itemize} \itemsep -2pt \item Highest honors in mathematics, high distinction in general scholarship.% \item GPA: 4.0 Math, 3.9 Physics, 3.9 cumulative. %\item Study Abroad Internship, A*STAR IHPC Singapore, Summer 2012. (See Research Experience.)
%\end{itemize}
\vspace{1pt}\section{Honors} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
Cognitive Science Society Robert J. Glushko Dissertation Prize, 2021 \\
Ric Weiland Graduate Fellowship in the Humanities and Sciences, 2018-2020 \\
National Science Foundation Graduate Research Fellowship, 2015-2018 \\
Percy Lionel Davis Award for Excellence in Scholarship in Mathematics, 2014 \\ 
Berkeley Physics Olsen Scholar 2013-2014 \\
Berkeley Letters \& Science Dean's List 2012-2014\\
Berkeley Physics Undergraduate Research Scholar, Spring \& Fall 2012
%\vspace{0pt}
\vspace{1pt}\section{Research\\Positions} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Senior Research Scientist,} DeepMind, March 2022 - Present\\ 
{\bf Research Scientist,} DeepMind, October 2020 - February 2022 
\begin{itemize} \itemsep -2pt
  \item Research on generalization, language, grounding, and memory. 
\end{itemize}\vspace{-8pt}
{\bf PhD Researcher,} Stanford University Department of Psychology, August 2015 - August 2020 
\begin{itemize} \itemsep -2pt
  \item Empirical and theoretical investigations of generalization, transfer, and abstraction in deep learning models. 
  \item Research on reducing the quantity of data required to train a deep learning system, including transfer, memory, and curriculum learning.
  \item Research on zero-shot performance of new tasks by transforming task representations.
  \item Experiments to investigate the effects of presentations of concepts on learning of related concepts in mathematical cognition.
\end{itemize}\vspace{-8pt}
{\bf PhD Intern,} DeepMind, May 2019 - September 2019
\begin{itemize} \itemsep -2pt
  \item Explored automated curriculum generation for goal-conditioned reinforcement learning.
  \item Explored generalization in reinforcement learning.
\end{itemize}\vspace{-8pt}
{\bf PhD Software Engineering Intern,} Google Brain, June 2017 - September 2017 
\begin{itemize} \itemsep -2pt
  \item Designed and developed a system for using low-quality data from human interactions to improve an adversarially trained image generative model. 
  \item Contributed gradients to TensorFlow image resizing ops.
\end{itemize}\vspace{-8pt}
{\bf Associate Professional Staff I,} Johns Hopkins University Applied Physics Laboratory, June 2014 - July 2015 
\begin{itemize} \itemsep -2pt
 \item Worked on image classification using convolutional neural networks. \item Developed models and simulations of sensor systems, shipping and transportation, and autoimmune diseases. \item Devised metrics for assessing sensors. \item Worked on methods for identifying malicious software based on its behavior. \end{itemize}\vspace{-8pt}
 {\bf Student Research Associate,} Lawrence Berkeley National Laboratories, January - May 2012 \& August - December 2012
\begin{itemize} \itemsep -2pt
  \item Developed simulations of processes in nuclear physics. \item Engineered software and hardware for efficiently collecting \& analyzing data. \end{itemize}\vspace{-8pt}
{\bf Summer Research Intern,} A*STAR Institute of High Performance Computing, Singapore, June - August 2012
\begin{itemize} \itemsep -2pt
  \item Wrote and adapted simulations of crystallization processes in super-cooled metals. \item Developed software for analyzing and visualizing the structure of crystals. \end{itemize}\vspace{-8pt}
{\bf Research Assistant,} UC Davis Plant Sciences, June - August 2011
 \begin{itemize} \itemsep -2pt
  \item Developed procedures and software for testing the physical attributes of fruit. \end{itemize}

\vspace{1pt}\section{Publications and Proceedings} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
\textbf{Andrew K. Lampinen}, Stephanie C. Y. Chan, Andrea Banino, Felix Hill (2021), {``Towards mental time travel: a hierarchical memory for reinforcement learning agents'',} \textit{Advances in Neural Information Processing Systems} \\[3pt] 
\textbf{Andrew K. Lampinen}, Stephanie C. Y. Chan, Adam Santoro, Felix Hill, (2021), {``Publishing fast and slow: A path towards generalizability in psychology and AI'',} Commentary in \textit{Behavioral and Brain Sciences} \\[3pt] 
\textbf{Andrew K. Lampinen} and James L. McClelland, (2020), {``Transforming task representations to allow deep learning models to perform novel tasks'',} \textit{Proceedings of the National Academy of Sciences} \\[3pt] 
Katherine L. Hermann* and \textbf{Andrew K. Lampinen}*, (2020), {``What shapes feature representations? Exploring datasets, architectures, and training'',} \textit{Advances in Neural Information Processing Systems}, (*equal contribution) \\[3pt] 
James L. McClelland, Bruce L. McNaughton, and \textbf{Andrew K. Lampinen} (2020), {``Integration of new information in memory: new insights from a complementary learning sytems perspective''}, \textit{Proceedings of the Royal Society B} \\[3pt]
S\'ebastien Racani\`ere*, \textbf{Andrew K. Lampinen}*, Adam Santoro, David P. Reichert, Vlad Firoiu, and Timothy P. Lillicrap, (2020), {``Automated curricula through setter-solver interactions'',} \textit{Proceedings of the 8th International Conference on Learning Representations}, (*equal contribution) \\ [3pt] 
Felix Hill, \textbf{Andrew K. Lampinen}, Rosalia Schneider, Stephen Clark, Matthew Bot-vinick, James L. McClelland, and Adam Santoro (2020), {``Environmental drivers of systematicity and generalisation in a situated agent'',} \textit{Proceedings of the 8th International Conference on Learning Representations} \\ [3pt] 
\textbf{Andrew K. Lampinen} and James L. McClelland, (2019), {``Zero-shot task adaptation by homoiconic meta-mapping'',} \textit{Learning Transferable Skills Workshop, NeurIPS} \\ [3pt] 
\textbf{Andrew K. Lampinen} and Surya Ganguli, (2019), {``An analytic theory of generalization dynamics and transfer learning in deep linear networks'',} \textit{Proceedings of the 7th International Conference on Learning Representations} \\[3pt] 
\textbf{Andrew K. Lampinen} and James L. McClelland, (2018), {``Different presentations of a mathematical concept can support learning in complementary ways'',} \textit{Journal of Educational Psychology} \\[3pt]
 Robert X. D. Hawkins, Eric N. Smith, Carolyn Au, Juan Miguel Arias, Rhia Catapano, Eric Hermann, Martin Keil, \textbf{Andrew Lampinen}, Sarah Raposo, Jesse Reynolds, Shima Salehi, Justin Salloum, Jed Tan, and Michael C. Frank, (2018), {``Improving the replicability of Psychological Science through pedagogy'',}  \textit{Advances in Methods and Practices in Psychological Science} \\ [3pt]
Steven S. Hansen, \textbf{Andrew K. Lampinen}, Gaurav Suri, and James L. McClelland, (2017), {``Building on prior knowledge without building it in'',} \textit{Commentary in Behavioral \& Brain Sciences}  \\[3pt]
\textbf{Andrew K. Lampinen}, Shaw Hsu, and James L. McClelland, (2017), {``Analogies emerge from learning dynamics in neural networks'',} \textit{Proceedings of the 39th Annual Meeting of the Cognitive Science Society}  

\vspace{1pt}\section{Preprints} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
Allison C. Tam, Neil C. Rabinowitz, \textbf{Andrew K. Lampinen}, Nicholas A. Roy, Stephanie C. Y. Chan, DJ Strouse, Jane X. Wang, Andrea Banino, Felix Hill (2022), {``Semantic Exploration from Language Abstractions and Pretrained Representations'',} \textit{arXiv} \\[3pt] 
\textbf{Andrew K. Lampinen}, Ishita Dasgupta, Stephanie C. Y. Chan, Kory Mathewson, Michael Henry Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, Felix Hill (2022), {``Can language models learn from explanations in context?'',} \textit{arXiv} \\[3pt] 
Stephanie C. Y. Chan*, \textbf{Andrew K. Lampinen}*, Pierre H. Richemond*, Felix Hill* (2022), {``Zipfian Environments for Reinforcement Learning'',} \textit{arXiv}, (*equal contribution) \\[3pt] 
\textbf{Andrew K. Lampinen}, Nicholas A. Roy, Ishita Dasgupta, Stephanie C. Y. Chan, Allison C. Tam, James L. McClelland, Chen Yan, Adam Santoro, Neil C. Rabinowitz, Jane X. Wang, Felix Hill (2021), {``Tell me why!---Explanations support learning of relational and causal structure'',} \textit{arXiv} \\[3pt] 
Adam Santoro*, \textbf{Andrew K. Lampinen*}, Kory Mathewson, Timothy Lillicrap, David Raposo, (2021), {``Symbolic Behaviour in Artificial Intelligence'',} \textit{arXiv}, (*equal contribution) \\[3pt] 
\textbf{Andrew K. Lampinen} and James L. McClelland, (2017), {``One-shot and few-shot learning of word embeddings'',} \textit{arXiv} \\[3pt] 
\textbf{Andrew K. Lampinen}, David So, Douglas Eck, and Fred Bertsch, (2017), {``Improving image generative models with human interactions'',} \textit{arXiv} 

\vspace{1pt}\section{Invited Talks} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{``Tell me why---Explanations improve learning of relational and causal structure'',} \textit{NYU Concepts \& Categories Seminar}, February 25th, 2022\\[3pt] 
{``A computational framework for learning and transforming task representations'',} \textit{Cognitive Science Society Glushko Dissertation Prize Talk}, July 29th, 2021\\[3pt] 
{``Task relationships, task transformations, and analogies'',} \textit{Analogical Minds Seminar}, May 13th, 2021\\[3pt] 
{``Multi-task learning, transfer, and abstraction'',} \textit{Parallel Distributed Processing and the Emergence of an Understanding of Mind}, Princeton University, September 29th, 2018\\[3pt] 
{``The Jabberwocky: One-shot and few-shot learning of word embeddings'',} \textit{Meaning in Context Workshop}, Center for the Study of Language and Information,  Stanford University, September 12th, 2017 
 
%\vspace{1pt}\section{Presentations} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
%{``Automated curricula through setter-solver interactions'',} \textit{8th International Conference on Learning Representations}, 2020 \\[3pt]
%{``Environmental drivers of systematicity and generalisation in a situated agent'',} \textit{8th International Conference on Learning Representations}, 2020 \\[3pt]
%{``Zero-shot task adaptation by homoiconic meta-mapping'',} \textit{Learning Transferable Skills Workshop, NeurIPS}, 2019 \\ [3pt] 
%{``An analytic theory of generalization dynamics and transfer learning in deep linear networks'',} Natural / Artificial Intelligence, Stanford Neurosciences Institute, 2018\\[3pt]
%{``An analytic theory of generalization dynamics and transfer learning in deep linear networks'',} Parallel Distributed Processing and the Emergence of an Understanding of Mind, Princeton University, 2018\\[3pt]
%{``Analogies emerge from learning dynamics in neural networks'',} 39th Annual Meeting of the Cognitive Science Society, 2017\\[3pt]
%{``Fast and sparse learning with compositional concept training'',} 15th Neural Computation and Psychology Workshop, 2016%\\[3pt]
%{``Cherenkov Radiation Based False Positive Detection for Rare Decays'',} Berkeley Undergraduate Physics Spring Poster Session, 2012

\vspace{1pt}\section{Teaching Experience} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Teaching Assistant,} Stanford University Department of Psychology, 6 courses between Fall 2016 and Winter 2019
\begin{itemize} \itemsep -2pt
  \item Planned and taught discussion sections for undergraduate statistics \& memory courses and graduate statistics \& research methods courses. \item Gave lectures on reinforcement learning and wrote and graded homeworks for graduate course on Neural Network Models of Cognition. \item Held office hours. \end{itemize}\vspace{-8pt}
{\bf Undergraduate Student Instructor,} UC Berkeley Mathematics, Spring, Fall 2013, \& Spring 2014 
\begin{itemize} \itemsep -2pt
  \item Planned and taught discussion sections. \item Held office hours. \item Wrote and graded quizzes and midterms. \end{itemize}\vspace{-8pt}
{\bf Teaching Assistant,} UC Berkeley Early Academic Outreach Program, June-July 2013
\begin{itemize} \itemsep -2pt
 \item Held office hours. \item Substitute taught classes. \end{itemize}

\vspace{1pt}\section{Other Work Experience} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Statistics Consultant,} Stanford University Department of Psychology, 2016-2017, 2019-2020
\begin{itemize} \itemsep -2pt
 \item Advised graduate students on technical aspects of data collection, analysis, and modeling. \end{itemize}
\vspace{1pt}\section{Service} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Reviewer:} 
\begin{itemize} \itemsep -2pt
 \item Artificial Intelligence
 \item Neural Information Processing Systems, 2020
 \item International Conference on Learning Representations, 2020- 
 \item International Conference on Machine Learning, 2021-
 \item Cognitive Science Society, 2019-
 \item Deep Reinforcement Learning Workshop at NeurIPS, 2020-
 \item Conference on the Mathematical Theory of Deep Neural Networks (DeepMath), 2019
 \item Journal of Educational Psychology
 \end{itemize}
%{\bf Outreach \& Mentoring:} 
%\begin{itemize} \itemsep -2pt
% \item Cientifico Latino Graduate Student Mentorship Initiative.
% \item ICLR 2022 Co-Submitting Summer. 
% \end{itemize}
\vspace{1pt}\section{Technical Skills} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Computer science:} Experienced with both theory and practice. 
\begin{itemize} \itemsep -2pt
  \item Graduate coursework in machine learning, neural networks, and probabilistic models \& algorithms.
  \item Experienced user of Python, R, C++, C, JavaScript, Matlab, some knowledge of Mathematica, Macaulay2, Haskell. 
  \item Used many common libraries for these languages, e.g. numpy, scipy, tidyr, dplyr, jquery, matplotlib, Matlab Computer Vision Toolbox, FFTW.
  \item Used many machine learning libraries, including TensorFlow, Torch, scikit-learn, and Caffe.
  \item Experienced with *NIX operating systems.
\end{itemize}\vspace{-8pt}
{\bf Mathematics:} Knowledge across many domains, with applications.
\begin{itemize} \itemsep -2pt
\item Algebraic geometry, group theory, category theory, topology, etc. \item Practical applications to machine learning, computer vision, neural coding, etc. \end{itemize}\vspace{-8pt}
{\bf Statistics:} Significant experience with standard data analysis techniques.
\begin{itemize} \itemsep -2pt
  \item Linear modeling, hierarchical modeling, etc.
  \item Fitting algorithms \& goodness-of-fit tests. \end{itemize} \vspace{-8pt}
{\bf Physics:} Experienced in a wide variety of applied and experimental contexts.\begin{itemize} \itemsep -2pt
\item Statistical mechanics, biophysics, analytic mechanics, etc. \item Experimentation ranging from NMR to quantum entanglement. \end{itemize}\vspace{-8pt}
{\bf Modeling \& Simulation:} Developed models and simulations of various phenomena. 
\begin{itemize} \itemsep -2pt
  \item Developed both from published methods and directly from physical principles. \end{itemize}
%{\bf Laboratory Equipment:} Competent with most common laboratory equipment. 
%\begin{itemize} \itemsep -2pt
% \item Oscilloscopes, standard \& lock-in amplifiers, signal generators, etc. \end{itemize} 
%%\vspace{-8pt}
%%{\bf Computer} Experienced with various operating systems and software applications.
%%\begin{itemize} \itemsep -2pt
%% \item Windows and Linux systems. \item Office, Photoshop \& Illustrator. \item  HTML \& \LaTeX.\end{itemize} 
\vspace{1pt}\section{Other Activities} \vspace{-15pt} \rule{\textwidth}{0.5pt} \\[3pt]
{\bf Carillon:} Carilloneur member of the Guild of Carilloneurs in North America (\url{www.gcna.org}). \\[3pt]
{\bf Rock climbing:} Bouldering, sport, and trad. Former routesetter at Stanford Climbing Wall, set problems for Collegiate Climbing Series events.

\end{resume}
\end{document} 



